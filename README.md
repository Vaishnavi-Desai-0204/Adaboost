# Adaboost

The given code defines two functions for training and testing an AdaBoost algorithm using decision tree weak learners. The adaboost_train function takes input features X, target values Y, and a maximum number of iterations for training. It initializes weights for each training sample, creates an empty list f to store weak learners, and alpha to store their corresponding weights. It then loops over the maximum iterations and fits a decision tree weak learner on the training data with sample weights proportional to the weights for each sample. It computes the prediction error weights and the corresponding alpha value, and updates the sample weights for the next iteration. Finally, it normalizes the sample weights and returns the trained list of weak learners and their corresponding alpha values.

The adaboost_test function takes the same input features X, target values Y, the trained list of weak learners f, and their corresponding alpha values. It loops over each test sample, computes the weighted sum of the weak learners' predictions, and returns the sign of the sum as the final prediction. It then compares the predicted values with the actual values to compute the accuracy of the model and returns it.
